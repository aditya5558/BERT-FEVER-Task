{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "claim_verification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-d_JcecYo5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os, tqdm, time, json\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDr7YWkrYo5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tokenization import FullTokenizer\n",
        "from Bert import *\n",
        "from scorer import fever_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjbIBnANYo5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGUmHMo1Yo5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_path = \"/content/drive/My Drive/NN-NLP-Project-Data/uncased_L-12_H-768_A-12/bert_model.ckpt\"\n",
        "vocab_file = \"/content/drive/My Drive/NN-NLP-Project-Data/uncased_L-12_H-768_A-12/vocab.txt\"\n",
        "model_name = \"ClaimVerification\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jErcqGykYo5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceDataset(Dataset):\n",
        "    def __init__(self, tok_ip, sent_ip, pos_ip, masks, y):\n",
        "        self.tok_ip = tok_ip\n",
        "        self.sent_ip = sent_ip\n",
        "        self.pos_ip = pos_ip\n",
        "        self.masks = masks\n",
        "        self.y = y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.tok_ip[index], self.sent_ip[index], self.pos_ip[index], self.masks[index], self.y[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5yFaW0wYo5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClaimVerification(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.enbedding_layer = EmbeddingLayer(config)\n",
        "        self.encoders = nn.ModuleList([EncoderLayer(config) for i in range(config.num_encoders)])\n",
        "        self.output = nn.Linear(config.emb_dim, 3)\n",
        "        \n",
        "    def forward(self, token_ip, sent_ip, pos_ip, mask=None):\n",
        "        embeddings = self.enbedding_layer(token_ip, sent_ip, pos_ip)\n",
        "        for encoder in self.encoders:\n",
        "            embeddings = encoder(embeddings, mask)\n",
        "        out = self.output(embeddings[:, 0])\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJX86P3HYo5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(fname):\n",
        "    label_dict = {}\n",
        "    label_dict['UNK'] = -1\n",
        "    label_dict['NOT ENOUGH INFO'] = 0\n",
        "    label_dict['SUPPORTS'] = 1\n",
        "    label_dict['REFUTES'] = 2\n",
        "    f = open(fname, encoding='utf8')\n",
        "    data = []\n",
        "    claim_ids = []\n",
        "    labels = []\n",
        "    predicted_evidence = []\n",
        "    for line in f:\n",
        "        line = json.loads(line)\n",
        "        sentence = [\"[CLS]\" + line['claim'] + \"[SEP]\", line['sentence'] + \"[SEP]\"]\n",
        "        label = label_dict[line['label']]\n",
        "        data.append(sentence)\n",
        "        labels.append(label)\n",
        "        claim_ids.append(line['id'])\n",
        "        predicted_evidence.append([line['doc'], line['sid']])\n",
        "    f.close()\n",
        "    \n",
        "    return data, labels, claim_ids, predicted_evidence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT_xf10kYo5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(data):\n",
        "    tokenizer = FullTokenizer(vocab_file)\n",
        "    tok_ip = np.zeros((len(data), 128), dtype=\"int16\")\n",
        "    sent_ip = np.zeros((len(data), 128), dtype=\"int16\")\n",
        "    pos_ip = np.zeros((len(data), 128), dtype=\"int16\")\n",
        "    masks = np.zeros((len(data), 128), dtype=\"float32\")\n",
        "    \n",
        "    for pos, text in tqdm.tqdm_notebook(enumerate(data)):\n",
        "        tok0 = tokenizer.tokenize(text[0])\n",
        "        tok1 = tokenizer.tokenize(text[1])\n",
        "        tok = tok0 + tok1\n",
        "        if len(tok) > 128:\n",
        "            tok = tok[:127] + [\"[SEP]\"]\n",
        "        pad_len = 128-len(tok)\n",
        "        tok_len = len(tok)\n",
        "        tok0_len = len(tok0)\n",
        "        tok = tokenizer.convert_tokens_to_ids(tok) + [0]*pad_len\n",
        "        pos_val = range(128)\n",
        "        sent = [0]*tok0_len + [1]*(tok_len-tok0_len) + [0]*pad_len\n",
        "        mask = [1]*tok_len + [0]*pad_len\n",
        "        \n",
        "        tok_ip[pos] = tok\n",
        "        pos_ip[pos] = pos_val\n",
        "        masks[pos] = mask\n",
        "        \n",
        "    masks = masks[:, None, None, :]\n",
        "    return tok_ip, sent_ip, pos_ip, masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVY1bbOxYo5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(\"train/train-tok.npy\"):\n",
        "    data, labels, ids, predicted_evidence = load_data(\"train-data.jsonl\")\n",
        "    tok_ip, sent_ip, pos_ip, masks = preprocess(data)\n",
        "    labels = np.array(labels)\n",
        "    os.mkdir(\"train\")\n",
        "    np.save(\"train/train-tok.npy\", tok_ip)\n",
        "    np.save(\"train/train-sent.npy\", sent_ip)\n",
        "    np.save(\"train/train-sent.npy\", pos_ip)\n",
        "    np.save(\"train/train-masks.npy\", masks)\n",
        "    np.save(\"train/train-labels.npy\", labels)\n",
        "else:\n",
        "    data, labels, ids, predicted_evidence = load_data(\"train-data.jsonl\")\n",
        "    tok_ip = np.load(\"train/train-tok.npy\")\n",
        "    sent_ip = np.load(\"train/train-sent.npy\")\n",
        "    pos_ip = np.load(\"train/train-sent.npy\")\n",
        "    masks = np.load(\"train/train-masks.npy\")\n",
        "    labels = np.load(\"train/train-labels.npy\")   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF1MH413Yo5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(\"dev/dev-tok.npy\"):\n",
        "    data_dev, labels_dev, ids_dev, predicted_evidence_dev = load_data(\"dev-data.jsonl\")\n",
        "    tok_ip_dev, sent_ip_dev, pos_ip_dev, masks_dev = preprocess(data_dev)\n",
        "    labels_dev = np.array(labels_dev)\n",
        "    os.mkdir(\"dev\")\n",
        "    np.save(\"dev/dev-tok.npy\", tok_ip_dev)\n",
        "    np.save(\"dev/dev-sent.npy\", sent_ip_dev)\n",
        "    np.save(\"dev/dev-pos.npy\", pos_ip_dev)\n",
        "    np.save(\"dev/dev-masks.npy\", masks_dev)\n",
        "    np.save(\"dev/dev-labels.npy\", labels_dev)\n",
        "else:\n",
        "    data_dev, labels_dev, ids_dev, predicted_evidence_dev = load_data(\"dev-data.jsonl\")\n",
        "    tok_ip_dev = np.load(\"dev/dev-tok.npy\")\n",
        "    sent_ip_dev = np.load(\"dev/dev-sent.npy\")\n",
        "    pos_ip_dev = np.load(\"dev/dev-pos.npy\")\n",
        "    masks_dev = np.load(\"dev/dev-masks.npy\")\n",
        "    labels_dev = np.load(\"dev/dev-labels.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm4CXSNdYo51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(\"test/test-tok.npy\"):\n",
        "    data_test, labels_test, ids_test, predicted_evidence_test = load_data(\"test-data.jsonl\")\n",
        "    tok_ip_test, sent_ip_test, pos_ip_test, masks_test = preprocess(data_test)\n",
        "    labels_test = np.array(labels_test)\n",
        "    os.mkdir(\"test\")\n",
        "    np.save(\"test/test-tok.npy\", tok_ip_test)\n",
        "    np.save(\"test/test-sent.npy\", sent_ip_test)\n",
        "    np.save(\"test/test-pos.npy\", pos_ip_test)\n",
        "    np.save(\"test/test-masks.npy\", masks_test)\n",
        "    np.save(\"test/test-labels.npy\", labels_test)\n",
        "else:\n",
        "    data_test, labels_test, ids_test, predicted_evidence_test = load_data(\"test-data.jsonl\")\n",
        "    tok_ip_test = np.load(\"test/test-tok.npy\")\n",
        "    sent_ip_test = np.load(\"test/test-sent.npy\")\n",
        "    pos_ip_test = np.load(\"test/test-pos.npy\")\n",
        "    masks_test = np.load(\"test/test-masks.npy\")\n",
        "    labels_test = np.load(\"test/test-labels.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvoM7U8DYo53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    loss_epoch = 0\n",
        "    for tok_ip, sent_ip, pos_ip, masks, y in tqdm.tqdm_notebook(loader):\n",
        "        optimizer.zero_grad()\n",
        "        tok_ip = tok_ip.type(torch.LongTensor).to(device)\n",
        "        sent_ip = sent_ip.type(torch.LongTensor).to(device)\n",
        "        pos_ip = pos_ip.type(torch.LongTensor).to(device)\n",
        "        masks = masks.to(device)\n",
        "        y = y.to(device)\n",
        "        O = model(tok_ip, sent_ip, pos_ip, masks)\n",
        "        loss = criterion(O, y)\n",
        "        loss_epoch += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print (\"Loss:\", loss_epoch/len(loader))\n",
        "    \n",
        "    return loss_epoch/len(loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFvkgobG9ice",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, loader):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    for tok_ip, sent_ip, pos_ip, masks, y in tqdm.tqdm_notebook(loader):\n",
        "        optimizer.zero_grad()\n",
        "        tok_ip = tok_ip.to(device)\n",
        "        sent_ip = sent_ip.to(device)\n",
        "        pos_ip = pos_ip.to(device)\n",
        "        masks = masks.to(device)\n",
        "        y = y.to(device)\n",
        "        output = model(tok_ip, sent_ip, pos_ip, masks)\n",
        "        outputs.extend(output.detach().cpu().argmax(dim=1).numpy())\n",
        "\n",
        "    return np.asarray(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-kfuJ8gBydU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merge predictions for each claim\n",
        "def merge_preds(preds, ids, predicted_evidence):\n",
        "    merged_preds = []\n",
        "    merged_evidence = []\n",
        "    cur_id = ids[0]\n",
        "    # Indices represent NEI, Supports, Refutes\n",
        "    stats = [0, 0, 0]\n",
        "    evidence_line = []\n",
        "    stats[preds[0]] += 1\n",
        "    for i in range(1,len(ids)):\n",
        "        if ids[i] == cur_id:\n",
        "            stats[preds[i]] += 1\n",
        "            evidence_line.append(predicted_evidence[i])\n",
        "        else:\n",
        "            # Label Assignment according to rules mentioned in paper\n",
        "            if stats[1] > 0:\n",
        "                merged_preds.append(\"SUPPORTS\")\n",
        "            elif stats[2] > 0 and stats[1] == 0:\n",
        "                merged_preds.append(\"REFUTES\")\n",
        "            elif stats[1] == 0 and stats[2] == 0:\n",
        "                merged_preds.append(\"NOT ENOUGH INFO\")\n",
        "            stats = [0, 0, 0]\n",
        "            cur_id = ids[i]\n",
        "            stats[preds[i]] += 1\n",
        "            merged_evidence.append(evidence_line)\n",
        "            evidence_line = []\n",
        "    if stats[1] > 0:\n",
        "        merged_preds.append(\"SUPPORTS\")\n",
        "    elif stats[2] > 0 and stats[1] == 0:\n",
        "        merged_preds.append(\"REFUTES\")\n",
        "    elif stats[1] == 0 and stats[2] == 0:\n",
        "        merged_preds.append(\"NOT ENOUGH INFO\")\n",
        "    merged_evidence.append(evidence_line)\n",
        "    return merged_preds, merged_evidence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqxp92G4J0Au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make final json with id, label, predicted_label, evidence and predicted_evidence\n",
        "def format_output(in_path, out_path, preds, evidence, dev=True):\n",
        "    outputs = []\n",
        "    with open(in_path, 'r', encoding='utf8') as f:\n",
        "        i = 0\n",
        "        for line in f.readlines():\n",
        "            output_obj = {}\n",
        "            input_obj = json.loads(line.strip())\n",
        "            output_obj['id'] = input_obj['id']\n",
        "            if dev:\n",
        "                output_obj['label'] = input_obj['label']\n",
        "            output_obj['predicted_label'] = preds[i]\n",
        "            output_obj['predicted_evidence'] = evidence[i]\n",
        "            if dev:\n",
        "                output_obj['evidence'] = input_obj['evidence']\n",
        "            i += 1\n",
        "            outputs.append(output_obj)\n",
        "\n",
        "    # Calculate Fever score for dev set\n",
        "    if dev:\n",
        "        print('Dev Set Results')\n",
        "        fever_sc, label_accuracy, precision, recall, f1 = fever_score(outputs)\n",
        "        print('Fever Score: ',fever_sc)     \n",
        "        print('Label Accuracy: ',label_accuracy)   \n",
        "        print('Precision: ',precision)       \n",
        "        print('Recall: ',recall)      \n",
        "        print('F1 Score: ',f1)    \n",
        "\n",
        "    # Write final predictions to file\n",
        "    with open(out_path, 'w', encoding='utf8') as f:\n",
        "        for line in outputs:\n",
        "            json.dump(line, f)\n",
        "            f.write(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYPYNg0SYo56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = SentenceDataset(tok_ip, sent_ip, pos_ip, masks, labels)\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32, num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUaRD_EBYo59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_dataset = SentenceDataset(tok_ip_dev, sent_ip_dev, pos_ip_dev, masks_dev, labels_dev)\n",
        "dev_loader = DataLoader(dev_dataset, shuffle=False, batch_size=32, num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuPBNdHmYo6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = SentenceDataset(tok_ip_test, sent_ip_test, pos_ip_test, masks_test, labels_test)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=32, num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HygPTFOXYo6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = Config()\n",
        "model = ClaimVerification(config)\n",
        "load_model(model, weights_path)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLViX1G7Yo6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train\n",
        "for i in range(1):\n",
        "    x = train(model, dev_loader, criterion, optimizer)\n",
        "    torch.save(model.state_dict(), model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpvmrSDajQmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dev Set\n",
        "preds = test(model, dev_loader)\n",
        "merged_preds, merged_evidence = merge_preds(preds, ids_dev, predicted_evidence_dev)\n",
        "format_output('dev.jsonl', 'dev_results.txt', merged_preds, merged_evidence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq-EeK5YkF29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test Set\n",
        "preds = test(model, test_loader)\n",
        "merged_preds, merged_evidence = merge_preds(preds, ids_dev, predicted_evidence_dev)\n",
        "format_output('test.jsonl', 'test_results.txt', merged\n",
        "_preds, merged_evidence)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}