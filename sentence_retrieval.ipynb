{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, tqdm, time, json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhinavk/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/abhinavk/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/abhinavk/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/abhinavk/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/abhinavk/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/abhinavk/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/abhinavk/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/abhinavk/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/abhinavk/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/abhinavk/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/abhinavk/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/abhinavk/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tokenization import FullTokenizer\n",
    "from Bert import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"uncased_L-12_H-768_A-12/bert_model.ckpt\"\n",
    "vocab_file = \"uncased_L-12_H-768_A-12/vocab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, tok_ip, sent_ip, pos_ip, masks, y):\n",
    "        self.tok_ip = tok_ip\n",
    "        self.sent_ip = sent_ip\n",
    "        self.pos_ip = pos_ip\n",
    "        self.masks = masks\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.tok_ip[index], self.sent_ip[index], self.pos_ip[index], self.masks[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceRetrieval(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.enbedding_layer = EmbeddingLayer(config)\n",
    "        self.encoders = nn.ModuleList([EncoderLayer(config) for i in range(config.num_encoders)])\n",
    "        \n",
    "        self.linear = nn.Linear(config.emb_dim, config.emb_dim)\n",
    "        self.drp = nn.Dropout(config.fc_drop_rate)\n",
    "        self.activation = GELU()\n",
    "        self.output = nn.Linear(config.emb_dim, 2)\n",
    "        \n",
    "    def forward(self, token_ip, sent_ip, pos_ip, mask=None):\n",
    "        embeddings = self.enbedding_layer(token_ip, sent_ip, pos_ip)\n",
    "        for encoder in self.encoders:\n",
    "            embeddings = encoder(embeddings, mask)\n",
    "        lin_out = self.activation(self.drp(self.linear(embeddings[:, 0])))\n",
    "        out = self.output(lin_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    f = open(fname, encoding='utf8')\n",
    "    data = []\n",
    "    labels = []\n",
    "    for line in f:\n",
    "        line = json.loads(line)\n",
    "        sentence = [\"[CLS]\" + line['claim'] + \"[SEP]\", line['sentence'] + \"[SEP]\"]\n",
    "        label = line['is_evidence']\n",
    "        data.append(sentence)\n",
    "        labels.append(label)\n",
    "    f.close()\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    tokenizer = FullTokenizer(vocab_file)\n",
    "    tok_ip = np.zeros((len(data), 512), dtype=\"long\")\n",
    "    sent_ip = np.zeros((len(data), 512), dtype=\"long\")\n",
    "    pos_ip = np.zeros((len(data), 512), dtype=\"long\")\n",
    "    masks = np.zeros((len(data), 512), dtype=\"long\")\n",
    "    \n",
    "    for pos, text in tqdm.tqdm_notebook(enumerate(data), total=len(data)):\n",
    "        tok0 = tokenizer.tokenize(text[0])\n",
    "        tok1 = tokenizer.tokenize(text[1])\n",
    "        tok = tok0 + tok1\n",
    "        if len(tok) > 512:\n",
    "            tok = tok[:511] + [\"[SEP]\"]\n",
    "        pad_len = 512-len(tok)\n",
    "        tok_len = len(tok)\n",
    "        tok0_len = len(tok0)\n",
    "        tok = tokenizer.convert_tokens_to_ids(tok) + [0]*pad_len\n",
    "        pos_val = range(512)\n",
    "        sent = [0]*tok0_len + [1]*(tok_len-tok0_len) + [0]*pad_len\n",
    "        mask = [1]*tok_len + [0]*pad_len\n",
    "        \n",
    "        tok_ip[pos] = tok\n",
    "        pos_ip[pos] = pos_val\n",
    "        masks[pos] = mask\n",
    "        break\n",
    "    \n",
    "    return tok_ip, sent_ip, pos_ip, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = load_data(\"dev-data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/abhinavk/Desktop/fever/tokenization.py:123: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2e1209ff904e5f968132ead0d858b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1163025), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_ip, sent_ip, pos_ip, masks = preprocess(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    loss_epoch = 0\n",
    "    for tok_ip, sent_ip, pos_ip, masks, y in tqdm.tqdm_notebook(loader):\n",
    "        optimizer.zero_grad()\n",
    "        tok_ip = tok_ip.to(device)\n",
    "        sent_ip = sent_ip.to(device)\n",
    "        pos_ip = pos_ip.to(device)\n",
    "        masks = masks.to(device)\n",
    "        y = y.to(device)\n",
    "        O = model(tok_ip, sent_ip, pos_ip, masks)\n",
    "        loss = criterion(O, y)\n",
    "        loss_epoch += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print (\"Loss:\", loss_epoch/len(loader))\n",
    "    \n",
    "    return loss_epoch/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentenceDataset(tok_ip, sent_ip, pos_ip, masks, labels)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=16, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceRetrieval(\n",
       "  (enbedding_layer): EmbeddingLayer(\n",
       "    (token_embeddings): Embedding(30522, 768)\n",
       "    (sentence_embeddings): Embedding(2, 768)\n",
       "    (positional_embeddings): Embedding(512, 768)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (emb_dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (encoders): ModuleList(\n",
       "    (0): EncoderLayer(\n",
       "      (self_attention): MultiHeadSelfAttentionLayer(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (gelu): GELU()\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): EncoderLayer(\n",
       "      (self_attention): MultiHeadSelfAttentionLayer(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (gelu): GELU()\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): EncoderLayer(\n",
       "      (self_attention): MultiHeadSelfAttentionLayer(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (gelu): GELU()\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): EncoderLayer(\n",
       "      (self_attention): MultiHeadSelfAttentionLayer(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (gelu): GELU()\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): EncoderLayer(\n",
       "      (self_attention): MultiHeadSelfAttentionLayer(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (gelu): GELU()\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): EncoderLayer(\n",
       "      (self_attention): MultiHeadSelfAttentionLayer(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (gelu): GELU()\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): EncoderLayer(\n",
       "      (self_attention): MultiHeadSelfAttentionLayer(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (gelu): GELU()\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): EncoderLayer(\n",
       "      (self_attention): MultiHeadSelfAttentionLayer(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (gelu): GELU()\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): EncoderLayer(\n",
       "      (self_attention): MultiHeadSelfAttentionLayer(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (gelu): GELU()\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): EncoderLayer(\n",
       "      (self_attention): MultiHeadSelfAttentionLayer(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (gelu): GELU()\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): EncoderLayer(\n",
       "      (self_attention): MultiHeadSelfAttentionLayer(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (gelu): GELU()\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): EncoderLayer(\n",
       "      (self_attention): MultiHeadSelfAttentionLayer(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (gelu): GELU()\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (drp): Dropout(p=0.1, inplace=False)\n",
       "  (activation): GELU()\n",
       "  (output): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config()\n",
    "model = SentenceRetrieval(config)\n",
    "load_model(model, weights_path)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abca257d52a8440eb9f801bb1723f56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=72690), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-17af42010110>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-ea7dfcf17ff4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok_ip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_ip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_ip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4abfdeb5daa6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ip, sent_ip, pos_ip, mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menbedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_ip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_ip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mlin_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlin_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/fever/Bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings, mask)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/fever/Bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, mask)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m10000.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mscores\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (16) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x = train(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
